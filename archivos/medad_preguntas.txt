001¬øQue contiene la diagonal de la matriz varianzas-covarianzas?
a. Las varianzas de las variables
b. Las covarianzas de las variables
c. La diagonal esta llena de 0
d. La diagonal esta llena de 1
a

002¬øCualquier multiplo de un autovector es de nuevo un autovector con el mismo autovalor asociado?
a. Verdadero
b. Falso
c.   
d.   
a

003¬øQue es una matriz semidefinida positiva?
a. Una matriz diagonal donde todos sus elementos son positivos
b. Una matriz cuadrada no simetrica donde todos sus autovalores son mayores o iguales a 0
c. Una matriz diagonal donde todos sus autovalores son mayores o iaguales a 0 
d. Una matriz cuadrada simetrica donde todos sus autovalores son mayores o iguales a 0
d

004Como se define la correlacion de dos variables
a. Varianza(a) / ( Covarianza(a, b) )
b. ( Covarianza(a, b) ) / Varianza(a)
c. (Varianza(a)^2 * Varianza(b)^2 ) / covarianzas(a, b)
d. Covarianza(a, b) / ( Varianza(a) * Varianza(b) )
d

005Como se puede obtener la matriz de correlaciones(P) a traves de la de var-cov(‚àë)
a. P = A‚àëA
b. P = A‚Åª¬π * ‚àë * A‚Åª¬π
c. P = A‚Åª¬π * ‚àë * A
d. P = A * ‚àë * A‚Åª¬π
b

006Dados dos variables aleatorias X1, con media 1 y varianza 2, y X2 con media 3 y varianza 8, y tal que la correlaci√≥n entre ambas es 0.25, entonces:
a. Var(X1 - X2) = 8
b. Var(2X1 - X2) = 2
c. Var(X1 + X2) = 10.5
d. Ninguna de las anteriores
a

007Las dos primeras componentes principales de un vector aleatorio:
a. Tienen mayor varianza que la suma de las restantes
b. Tienen correlaci√≥n cero
c. No cambian si estandarizamos todas las variables
d. Ninguna de las anteriores
b

008Cuando no disponemos de los valores muestrales de las variables originales sino tan solo de las distancias entre puntos de la muestra en un an√°lisis cluster:
a. Puede usarse el m√©todo del centroide
b. No puede usarse el m√©todo del encadenamiento simple
c. Puede usarse el m√©todo del encadenamiento completo
d. Ninguna de las anteriores
c

009Denotando por Z1 y Z2, la primera y segunda componente principal de un vector aleatorio con matriz var-cov Œ£, indicar cu√°l de las siguientes afirmaciones puede darse:
a. Var(Z1) = 3; Var(Z2) = 4
b. Var(Z2) > 1/2tr(Œ£)
c. Var(Z1) = Var(Z2) = 100
d. Ninguna de las anteriores
c

010El m√©todo de las k-medias:
a. Puede implementarse mediante un dendograma
b. Ofrece la misma soluci√≥n cuando todas las variables originales se multiplican por una misma constante
c. Llega a la misma soluci√≥n si estandarizamos las variables
d. Ninguna de las anteriores
b

011Sea (X1, X2)^T un vector aleatorio con distribuci√≥n N2 matrix(1;2), matrix[[3, 3], [3, 5]], entonces la distribuci√≥n de 2X1 - X2 es:
a. N(0, 5)
b. N((0; 0), [[12, -6], [-6, 5]])
c. N(0, 8)
d. Ninguna de las anteriores
a

012Para calcular un dendograma:
a. Podemos utilizar cualquier m√©todo jer√°rquico
b. Basta con conocer las distancias entre los puntos de la muestra, si el m√©todo de agrupaci√≥n es el de encadenamiento completo
c. Si, en cualquier caso
d. Ninguna de las anteriores
b

013El m√©todo de las k-medias de MacQueen recalcula los centroides:
a. Tras cada asignaci√≥n
b. Utilizando CP
c. Solo al principio y al final del algoritmo
d. Ninguna de las anteriores
a

014Dada la distancia de Mahalanobis, d, entre dos vectores x e y, y un escalar a > 0:
a. d(...) = a * d(x, y)
b. d(...) = a^t * Z^-1 * a
c. d(...) = a^2 * d(x, y)
d. Ninguna de las anteriores
a

015La primera componente principal tiene por coeficientes:
a. El autovector correspondiente al autovalor mayor de Œ£^-1
b. El autovalor mayor
c. El autovector correspondiente al autovalor mayor de Œ£
d. Ninguna de las anteriores
c

016¬øPuede ser (4, -3, -3.2) la matriz var-cov de un vector aleatorio X?
a. S√≠, si p(x1, x2) = -3 / (2 sqrt(2))
b. No puede serlo
c. S√≠, en cualquier caso
d. Ninguna de las anteriores
b

017Dado un vector aleatorio con matriz var-cov [[3, 3], [3, 5]], las varianzas de sus componentes principales Z1 y Z2 son:
a. Var(Z1) = 4 + sqrt(10); Var(Z2) = 4 - sqrt(10)
b. Var(Z1) = 5; Var(Z2) = 3
c. Var(Z1) = 1/2; Var(Z2) = 5/6
d. Ninguna de las anteriores
a

018Denotando por dij la distancia ultram√©trica entre las observaciones i y j en un dendograma, y sabiendo que d43 = 25 y d47 = 35, ¬øcu√°l de las situaciones puede darse?
a. d(3, 7) = 25
b. d(3, 7) = 35
c. d(3, 7) = 20
d. Ninguna de las anteriores
b

019El problema del escalamiento multidimensional:
a. Tiene tantas soluciones como filas tiene la matriz de distancias
b. Tiene soluci√≥n √∫nica siempre
c. D = [[0, 1, 1], [1, 0, 1], [1, 1, 0]] tiene como soluci√≥n los puntos (0, 0), (1, 0), (1/2, sqrt(3)/2)
d. Ninguna de las anteriores
c

020Si en el m√©todo de las k-medias multiplicamos todos los datos por un mismo vector a > 0:
a. Pasaremos a encontrar k * a grupos
b. Si a > 1, los datos originalmente m√°s cercanos...
c. Los k grupos obtenidos no var√≠an
d. Ninguna de las anteriores
c

021Un algoritmo para elegir los puntos semilla iniciales en el m√©todo de las k-medias es:
a. El de m√°xima verosimilitud
b. El algoritmo de Ball y Hall
c. El algoritmo single linkage
d. Ninguna de las anteriores
b

022Para hacer clasificaci√≥n no supervisada es √∫til:
a. Un escalamiento multidimensional sobre las correlaciones
b. La estimaci√≥n tipo n√∫cleo
c. Calcular los autovalores...
d. Ninguna de las anteriores
b

023El an√°lisis factorial trata de expresar el vector aleatorio de partida, X, de la forma:
a. X = B √ó Bt + Œ®, donde B es p √ó k y Œ® es una matriz diagonal
b. Z = (Bt √ó B)^(-1)
c. X = B √ó F + U, donde F es un vector de k factores
d. Ninguna de las anteriores
c

024Los cuadrados de los coeficientes de correlaci√≥n de un conjunto de variables pueden usarse:
a. Como similitudes para realizar un an√°lisis cluster entre variables
b. Para realizar un an√°lisis cluster entre los datos de una muestra
c. Para calcular sus componentes principales
d. Ninguna de las anteriores
a

025Dadas tan solo las discrepancias entre los elementos de una muestra, una t√©cnica que permite representar los datos como puntos en un espacio de dimensi√≥n baja es:
a. El escalamiento multidimensional
b. El an√°lisis factorial
c. ACP
d. Ninguna de las anteriores
a

026Dado vectores aleatorios X e Y con Yi = (Xi - Œºi) -ùúéi, i = 1, 2, ..., p. Sus matrices de Var-cov ‚àëx y ‚àëy y de correlaciones Rx y Ry cumplen:
a. ‚àëx = ‚àëy
b. Rx = ‚àëy
c. ‚àëx = Ry
d. Ninguna es correcta
b

027Sea (X1, X2)^t un vector aleatorio de distribucion: N2(  ([1], [1])  ,  ([3, 1], [1, 2])  ), la distribucion de X1-X2 es:
a. N(0, 3)
b. N2( ([0, 0]) , ([1, 0], [0, 1]) )
c. N(0, 5)
d. Ninguna es correcta
a

028Deotado por Z1 y Z2 la primera y segunda componente principal de un vector aleatorio con matriz var-cov ‚àë, que afirmacion puede darse:
a. Var(Z1) = 3, Var(Z2) = 4
b. Var(Z1 + Z2) > tr(‚àë)
c. Var(Z1) = 0.001, Var(Z2) = 0.001
d. Ninguna opcion es correcta
c

029La segunda componente principal de un vector aleatorio X con la matriz var-cov ‚àë, es de la forma Z2 = a^tX con:
a. a segundo mayor autovector de ‚àë
b. a un autovector asociado al segundo mayor autovalor de ‚àë
c. a = ‚àë^t*X
d. Ninguna opcion es correcta
b

030La probabilidad de clasificaci√≥n incorrecta
a. Es una funci√≥n que asigna a cada observaci√≥n su grupo de pertenencia
b. Solo depende de la muestra obtenida
c. Cambia con cada regla de clasificaci√≥n
d. Ninguna opcion es correcta 
c

031Las combinaciones lineales que mejor permiten separar los grupos pueden calcularse mediante
a. An√°lisis factorial discriminante
b. An√°lisis de componentes principales
c. An√°lisis cluster
d. Ninguna opcion es correcta
a

032La regla de clasificaci√≥n que asigna iuna nueva observaci√≥n con centroide con distancia de mahalanobis menor coincide
a. Con la regla de Bayes con probabilidades a priori diferentes
b. Con la regla de vecinos m√°s cercanos
c. Con la regla de m√°ximo veros√≠mil, bajo la normalidad
d. Ninguna opcion es correcta  
c

033La regla del discriminante lineal de Fisher se calcula
a. Utilizando un m√©todo de regresi√≥n lineal
b. Proyectando seg√∫n los factores discriminantes
c. Proyectando seg√∫n la primera componente principal
d. Ningunaopcion es correcta
b

034La regla de clasificaci√≥n de Bayes es la que asigna una futura observaci√≥n,vector de x, al grupo i
a. Que tiene mayor probabilidad P(X = x|Y = i)
b. Con centroide a distancia de mahalanobis
c. Con mayor probabilidad P(X = x| Y = i)
d. Ninguna opcion es correcta
a

034El error aparente de una regla de clasificaci√≥n es
a. La proporci√≥n de veces en las que comete error cuando se eval√∫a sobre la propia muestra usada para contruirla
b. La diferencia entre el error de clasificaci√≥n y su media
c. El menor error de clasificaci√≥n posible
d. Ninguna opcion es correcta  
a

035Al contrastar cuatro hip√≥tesis nulas los p-valores obtenidos para cada una fueron(a,b,c,d): 0.0363 para H0a, 0.0024 para H0b, 0.00162 para H0c y 0.2491 para H0d. En un contexto de contrastes m√∫ltiples, con nivel de significaci√≥n 0.05 las √∫nicas hip√≥tesis nulas que se rechazar√≠an son
a. H0a y H0b usando el m√©todo de Simes 
b. H0b y H0c usando el m√©todo de Hochberg
c. H0a, H0b y H0c usando el m√©todo de Hochberg
d. Ninguan opcion es correcta
b

036La probabilidad de clasificaci√≥n incorrecta
a. Es una funci√≥n que asigna a cada observaci√≥n su grupo de pertenencia
b. Solo depende de la muestra obtenida
c. Cambia con cada regla de clasificaci√≥n
d. Ninguan opcion es correcta
c

037Las combinaciones lineales que mejor permiten separar los grupos pueden calcularse mediante
a. An√°lisis factorial discriminante
b. An√°lisis de componentes principales
c. An√°lisis cluster
d. Ninguan opcion es correcta
a

038La regla de clasificaci√≥n que asigna iuna nueva observaci√≥n con centroide con distancia de mahalanobis menor coincide
a. Con la regla de Bayes con probabilidades a priori diferentes
b. Con la regla de vecinos m√°s cercanos
c. Con la regla de m√°ximo veros√≠mil, bajo la normalidad
d. Ninguan opcion es correcta  
c

039La regla del discriminante lineal de Fisher se calcula
a. utilizando un m√©todo de regresi√≥n lineal
b. proyectando seg√∫n los factores discriminantes
c. proyectando seg√∫n la primera componente principal
d. Ninguan opcion es correcta    
b

040La regla de clasificaci√≥n de Bayes es la que asigna una futura observaci√≥n,vector de x, al grupo i
a. Que tiene mayor probabilidad P(X = x|Y = i)
b. Con centroide a distancia de mahalanobis
c. Con mayor probabilidad P(X = x| Y = i)
d. Ninguan opcion es correcta 
a

041El error aparente de una regla de clasificaci√≥n es
a. La proporci√≥n de veces en las que comete error cuando se eval√∫a sobre la propia muestra usada para contruirla
b. La diferencia entre el error de clasificaci√≥n y su media
c. El menor error de clasificaci√≥n posible
d. Ninguan opcion es correcta    
a

042Al contrastar cuatro hip√≥tesis nulas los p-valores obtenidos para cada una fueron(a,b,c,d): 0.0363 para H0a, 0.0024 para H0b, 0.00162 para H0c y 0.2491 para H0d. En un contexto de contrastes m√∫ltiples, con nivel de significaci√≥n 0.05 las √∫nicas hip√≥tesis nulas que se rechazar√≠an son
a. H0a y H0b usando el m√©todo de Simes 
b. H0b y H0c usando el m√©todo de Hochberg
c. H0a, H0b y H0c usando el m√©todo de Hochberg
d. Ninguan opcion es correcta   
b

043Cuando se est√°n contrastando k hip√≥tesis nulas, con nivel de significaci√≥n alfa ,la FWER del m√©todo de Simes es
a. Menor igual que alfa/2
b. Alfa, si las hip√≥tesis nulas son ciertas y los contrastes independientes
c. Menor que la FWER del m√©todo de Hochberg
d. Ninguan opcion es correcta     
b

044El m√©todo de regresi√≥n riscal (ridge regression) penaliza l complejidad del modelo mediante
a. La suma de los cuadrados de sus coeficientes
b. La suma de valores absolutos de sus coeficientes
c. El n√∫mero de coeficientes nulos
d.   
a

045Dados los vectores aleatorios ùëã‚Éó y ùëå‚Éó‚Éó con Yi = (Xi ‚Äì ùúái)/ùúéi, i = 1, ‚Ä¶, p, sus matrices de varianzas-covarianzas, Œ£X y Œ£Y y de correlaciones RX y RY cumplen:
a. Œ£X = Œ£Y
b. RX = Œ£Y
c. Œ£X = RY
d. Ninguan opcion es correcta 
b

046Sea (X1, X2)t un vector aleatorio con distribuci√≥n: N2((1 1), (3 1 1 2)) , entonces la distribuci√≥n X1 -X2 es:
a. N(0, 3)
b. N2((0 0), (1 0 0 1))
c. N(0, 5)
d. Ninguan opcion es correcta
a  

047Denotando por Z1 y Z2 la primera y segunda componentes principales de un vector aleatorio con matriz de varianzas-covarianzas Œ£, indicar cu√°l de las siguientes afirmaciones puede darse
a. Var(Z1) = 3, Var(Z2) = 4
b. Var(Z1) + Var(Z2) > tr(Œ£)
c. Var(Z1) = 0.001, Var(Z2) = 0.001
d. Ninguan opcion es correcta
c

048La segunda componente principal de un vector aleatorio, ùëã‚Éó , con matriz de varianzas-covarianzas Œ£, es de la forma Z2=ùëé‚Éó tùëã‚Éó con:
a. ùëé‚Éó el segundo mayor autovector de Œ£
b. ùëé‚Éó un autovector asociado al segundo mayor autovalor de Œ£
c. ùëé‚Éó = Œ£tùëã‚Éó
d. Ninguan opcion es correcta
b 

049Dado un vector aleatorio con matriz de varianzas-covarianzas Œ£ = (3 1 1 2), las varianzas de sus componentes principales, Z1 y Z2 son:
a. Var(Z1) = (5+‚àö5) 2 , Var(Z2) = (5‚àí‚àö5)2
b. Var(Z1) = 3, Var(Z2) = 2
c. Var(Z1) = 7 2, Var(Z2) = 3
d.    
a

050El llevar a cabo el an√°lisis de componentes principales sobre la matriz de correlaciones puede ser √∫til porque:
a. No cambia con los cambios de escala
b. Siempre equivale a hacerlo sobre la de varianzas-covarianzas
c. Equivale a hacerlo sobre la de varianzas-covarianzas si las variables est√°n medidas en las mismas unidades
d. Ninguan opcion es correcta   
a

051Tras llevar a cabo un ACP sobre la matriz de correlaciones de un vector aleatorio de dimensi√≥n 10 y denotando por Z1 la primera componente principal, indicar cu√°l de las siguientes afirmaciones puede ocurrir:
a. Var(Z1) = 12
b. Var(Z1) = 0.9
c. Var(Z1) = 2
d.   
c

052El objetivo del escalamiento multidimensional es:
a. Maximizar la variabilidad del conjunto de datos
b. Minimizar las correlaciones entre las nuevas variables
c. Representar los datos como puntos en un espacio de dimensi√≥n baja
d. Ninguan opcion es correcta  
c

053La informaci√≥n de entrada para realizar un escalamiento multidimensional ha de ser necesariamente
a. Una muestra de datos sobre los que se han medido p variables
b. Una matriz de discrepancias o similitudes entre los elementos de una muestra
c. La matriz de varianzas-covarianzas de ùëã‚Éó
d. Ninguan opcion es correcta
b

054¬øPuede ser (3 2 2 1) la matriz de varianzas-covarianzas de un vector aleatorio ùëã‚Éó ?
a. S√≠, en cualquier caso
b. S√≠, si p(X1, X2) = 2/3
c. No puede serlo
d. Ninguan opcion es correcta  
c

055La distancia de Mahalanobis entre ùë•‚Éó e ùë¶‚Éó es:
a. [(ùë•‚Éó - ùë¶‚Éó )tŒ£-1(ùë•‚Éó - ùë¶‚Éó )]1/2
b. (ùë•‚Éó - ùë¶‚Éó )t(ùë•‚Éó - ùë¶‚Éó )
c. (ùë•‚Éó - ùë¶‚Éó )t Œ£1/2(ùë•‚Éó - ùë¶‚Éó )
d. Ninguan opcion es correcta   
c

056Un dendograma es el resultado de aplicar
a. Un m√©todo jer√°rquico de clasificaci√≥n supervisada
b. Un m√©todo no jer√°rquico de clasificaci√≥n no supervisada
c. Un m√©todo jer√°rquico de clasificaci√≥n no supervisada
d. Ninguan opcion es correcta
c

057Al realizar un an√°lisis cluster, considerando dos grupos A y B formados en cierta etapa y las distancias entre grupos calculadas mediante el m√©todo del encadenamiento simple (dES) y el encadenamiento completo (dEC), se tiene:
a. dES(A, B) ‚â• dEC(A, B)
b. dES(A, B) ‚â§ dEC(A, B)
c. dES(A, B) ‚â§ dEC(A, B)2
d. Ninguan opcion es correcta
b

058Para realizar un an√°lisis cluster entre variables podemos partir de:
a. Sus correlaciones como distancias entre ellas
b. Los cuadrados de sus correlaciones como similitudes entre ellas
c. Los cuadrados de sus correlaciones como distancias entre ellas
d. Ninguan opcion es correcta   
b

059Un algoritmo para elegir los puntos semilla iniciales en el m√©todo de las k medias es.
a. El algoritmo de Astrahan
b. El algoritmo single linkage
c. El an√°lisis de componentes principales
d. Ninguan opcion es correcta  
a  

060El m√©todo de las k medias de MacQueen recalcula los centroides
a. Tras cada ciclo completo de asignaciones
b. Tras cada asignaci√≥n
c. Solo al final del algoritmo
d. Ninguan opcion es correcta
b   

061¬øCu√°l de los siguientes m√©todos puede usarse para la clasificaci√≥n no supervisada?
a. El m√©todo de las k medias
b. El escalamiento multidimensional
c. El an√°lisis de componentes principales
d. Ninguan opcion es correcta
a     

062La estimaci√≥n tipo n√∫cleo (o kernel) es √∫til para
a. Realizar un an√°lisis de componentes principales
b. Hacer clasificaci√≥n no supervisada
c. Llevar a cabo escalamiento multidimensional
d. Ninguan opcion es correcta  
b   

063Denotando por d*ij la distancia ultram√©trica entre las observaciones i y j en un dendograma, y sabiendo que d*23 = 5, d*25 = 7, ¬øcu√°l de las siguientes situaciones puede darse?
a. d*35 = 4
b. d*35 = 5
c. d*35 = 7
d. Ninguan opcion es correcta  
c
